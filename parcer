#! /bin/bash

source ./rsaver.cfg

#Final file (NH_topics) rotation
NH_rotate () {
if [ -s NH_topics ];then
        if [ -d ./log ];then
                echo './log exists'
                cat NH_topics > ./log/NH_topics_$(date +%F-%s)
		rm *
		echo "NH topics rotated"
		sleep 1
	else
		mkdir ./log
		cat NH_topics > ./log/NH_topics_$(date +%F-%s)
                rm *
		echo '/log initialized, NH topics rotated'
		sleep 1
	fi
else
	rm *
fi
}

# initializing tmp folder, and verifying created one.
if [ -d ./.r_tmp ]; then
	echo './r_tmp exists'
	cd ./.r_tmp && NH_rotate
	sleep 1
else
	mkdir ./.r_tmp
	cd ./.r_tmp
	echo './r_tmp initialized'
	sleep 1
fi

if [ -d /var/log/rsaver_log ]; then
	echo '/var/log/exists'
	sleep 1
else
	mkdir /var/log/rsaver_log
	echo '/var/log/ initialized'
	sleep 1
fi

start_time=$(date)

# scraping forum links

wget https://rutracker.org/forum/index.php
if [ -e index.php ]; then
	if [ -e index_scrape ]; then
		mv index_scrape index_scrape_$(date +%F-%s)
	fi
	iconv -f cp1251 index.php | grep -a viewforum.php | sed -r 's/.+(.+viewforum.php\?f=)//' | cut -d "\"" -f 1 | sort -n | uniq > index_scrape
	rm index.php
fi

# scraping RECURSIVE forum links , but there is annoying bug (though there are a lot of uniq everywhere, but final list isn`t uniq)

forum_count=$(cat index_scrape | wc -l)
i=o

until ((i == $forum_count));do
	forum_id=$(cat index_scrape | awk NR==$i)
	clear
	cat index_scrape | wc
	echo "Scraping forum $i from $forum_count"
	wget --output-document="forum.html" "https://rutracker.org/forum/viewforum.php?f=$forum_id"
	iconv -f cp1251 forum.html | grep -a viewforum.php | sed -r 's/.+(.+viewforum.php\?f=)//' | cut -d "\"" -f 1 | cut -d "'" -f1 | cut -d"&" -f 1 | sort -n | uniq > forum_scrape
	cat index_scrape forum_scrape | sort -n | uniq > uniq_scrape
	cat index_scrape | sort -n | uniq > index_scrape_sort
	comm -13 index_scrape_sort uniq_scrape 2>/dev/null >> index_scrape
	forum_count=$(cat index_scrape | wc -l)
	sleep $sleep_t
	((++i))
done

# kostyl` to hotfix previous bug

cat index_scrape | sort -n | uniq > final_scrape && rm index_scrape

# cleaning temp files & logging

rm forum_scrape forum.html index_scrape_sort uniq_scrape
echo "[DEBUG][SCRAPER] Forum scraping; Start: $start_time; End: $(date); Forums scraped $(cat final_scrape | wc -l); " >>/var/log/rsaver_log/rsaver.log

# scraping pages for topic lists

start_time=$(date)
forum_count=$(cat final_scrape | wc -l)
i=o

until ((i == $forum_count));do
        forum_id=$(cat final_scrape | awk NR==$i)
        while true; do
                wget --output-document="page.html" "https://rutracker.org/forum/viewforum.php?f=${forum_id}&start=$pages"
                error_p=$(iconv -f cp1251 page.html | grep "Подходящих тем или сообщений не найдено")
                if [ "$error_p" ]; then
                        clear
                        echo "Error 404: $error_p"
                        error_p=$devnull
                        pages=0
                        sleep $sleep_t
                        break
                else
                        if [ -s page.html ]; then
                                cat page.html | grep -a "viewtopic.php?t" | cut -d" " -f5 | grep view | sed -r 's/^[^[0-9]+//' | sed -r 's/.$//' >> page_scrape
                                rm page.html
                                pages=$((pages+50))
                                clear
                                echo "$( cat page_scrape | wc -l ) topic link parsed"
                                echo "$forum_id from $forum_count forums parced"
                        else
                                break
                        fi
                fi
        sleep $sleep_t
        done
        ((++i))
done

cat page_scrape | sort -n | uniq > topic_scrape && rm page_scrape 
echo "[DEBUG][SCRAPER] Topic scraping; Start: $start_time; End: $(date); Topics scraped: $(cat topic_scrape | wc -l);" >> /var/log/rsaver_log/rsaver.log

# scraping topics and saving final file

start_time=$(date)
topic_count=$(cat topic_scrape | wc -l)
i=0

until ((i == $topic_count));do
        topic_id=$(cat topic_scrape | awk NR==$i)
        clear
        echo "Scraping topic $i from $topic_count"
        wget --output-document="topic.html" --load-cookies=$wget_cookies "https://rutracker.org/forum/viewtopic.php?t=$topic_id"
        if [ -s topic.html ]; then
                t_seeds=$(iconv -f cp1251 topic.html | grep "Сиды" | cut -d ">" -f 3 | sed -r 's/[^[0-9]*$//')
                t_size=$(iconv -f cp1251 topic.html | grep "Размер" | awk NR==1 | cut -d ">" -f 2  | sed -r 's/[^[0-9]*$//')
                t_degree=$(iconv -f cp1251 topic.html | grep "Размер" | awk NR==1 | cut -d ">" -f 2  | cut -d ";" -f 2 | sed -r 's/[^[B]*$//')
                t_magnet=$(iconv -f cp1251 topic.html | grep magnet: | sed -r 's/^[^"]*//'| cut -d" " -f1)
                if [ "$t_seeds" ] && [ "$t_size" ] && [ "$t_degree" ] && [ "$t_magnet" ]; then
                        if (($t_seeds == 1)) && (($(echo "$t_size > $t_size_min" | bc) ==1)) && (($(echo "$t_size < $t_size_max" | bc) ==1)) && [ $t_degree == "GB" ] ; then
                                 echo "${topic_id};${t_magnet};${t_size};" >> NH_topics
                                 clear
                                 echo "Nice one!"
				 t_nice=$(($t_nice + 1))
                                 sleep $sleep_t
                        elif (($t_seeds != 1)); then
                                clear
                                echo "Seeds number is too low or too high"
                                sleep $sleep_t
				t_bad=$(($t_bad + 1))
                        elif (($(echo "$t_size < $t_size_min" | bc) ==1)) || [ $t_degree != "GB" ]; then
                                clear
                                echo "Size is too small"
                                sleep $sleep_t
				t_bad=$(($t_bad + 1))
                        elif (($(echo "$t_size > $t_size_max" | bc) ==1)); then
                                clear
                                echo "Size is too big"
                                sleep $sleep_t
				t_bad=$(($t_bad + 1))
                        else
                                clear
                                echo "BAD conditions"
                                echo "[ERROR][CONDITIONS]${topic_id};${t_magnet};${t_size}${t_degree};${t_seeds};" >> BAD_topics
                                sleep $sleep_t
				t_bad=$(($t_bad + 1))
                        fi
                else
                        clear
                        echo "BAD topic"
                        sleep $sleep_t
			t_bad=$(($t_bad + 1))
                fi
                rm topic.html
                t_seeds=$devnull
                t_size=$devnull
                t_degree=$devnull
                t_magnet=$devnull
        fi
        ((++i))
done

rm topic_scrape
echo "[DEBUG][SCRAPER] Torrent scraping; Start: $start_time; End: $(date); Torrent scraped: $t_nice; Useless torrents: $t_bad" >> /var/log/rsaver_log/rsaver.log
