#! /bin/bash

# initializing tmp folder, and verifying created one.

if [ -d /tmp/rutr_saver_tmp ]; then
	cd /tmp/rutr_saver_tmp
else
	mkdir /tmp/rutr_saver_tmp
	cd /tmp/rutr_saver_tmp
fi

start_time=$(date)

# scraping forum links

wget https://rutracker.org/forum/index.php
if [ -e index.php ]; then
	if [ -e index_scrape ]; then
		mv index_scrape index_scrape_$(date +%F-%s)
	fi
	iconv -f cp1251 index.php | grep -a viewforum.php | sed -r 's/.+(.+viewforum.php\?f=)//' | cut -d "\"" -f 1 | sort -n | uniq > index_scrape
	rm index.php
fi

# scraping RECURSIVE forum links , but there is annoying bug (though there are a lot of uniq everywhere, but final list isn`t uniq)

forum_count=$(cat index_scrape | wc -l)
i=o
cat index_scrape > index_scrape_t0

until ((i == $forum_count));do
	forum_id=$(cat index_scrape | awk NR==$i)
	clear
	cat index_scrape | wc
	echo "Scraping forum $i from $forum_count"
	wget --output-document="forum.html" "https://rutracker.org/forum/viewforum.php?f=$forum_id"
	iconv -f cp1251 forum.html | grep -a viewforum.php | sed -r 's/.+(.+viewforum.php\?f=)//' | cut -d "\"" -f 1 | cut -d "'" -f1 | cut -d"&" -f 1 | sort -n | uniq > forum_scrape
	cat index_scrape forum_scrape | sort -n | uniq > uniq_scrape
	cat index_scrape | sort -n | uniq > index_scrape_sort
	comm -13 index_scrape_sort uniq_scrape 2>/dev/null >> index_scrape
	forum_count=$(cat index_scrape | wc -l)
	sleep 0.2
	((++i))
done

# kostyl` to hotfix previous bug

cat index_scrape > index_scrape_t1
cat index_scrape | sort -n | uniq > final_scrape && rm index_scrape

# cleaning temp files & logging

rm forum_scrape forum.html index_scrape_sort uniq_scrape
echo "[DEBUG][SCRAPER] Forum scraping; Start: $start_time; End: $(date); Forums scraped $(cat final_scrape | wc -l); " >> rutrsaver.log

# scraping pages for topic lists

start_time=$(date)
forum_count=$(cat final_scrape | wc -l)
i=o

until ((i == $forum_count));do
        forum_id=$(cat final_scrape | awk NR==$i)
        while true; do
                wget --output-document="page.html" "https://rutracker.org/forum/viewforum.php?f=${forum_id}&start=$pages"
                error_p=$(iconv -f cp1251 page.html | grep "Подходящих тем или сообщений не найдено")
                if [ "$error_p" ]; then
                        clear
                        echo "Error 404: $error_p"
                        error_p=$devnull
                        pages=0
                        sleep 0.5
                        break
                else
                        if [ -s page.html ]; then
                                cat page.html | grep -a "viewtopic.php?t" | cut -d" " -f5 | grep view | sed -r 's/^[^[0-9]+//' | sed -r 's/.$//' >> page_scrape
                                rm page.html
                                pages=$((pages+50))
                                clear
                                echo "$( cat page_scrape | wc -l ) topic link parsed"
                                echo "$forum_id from $forum_count forums parced"
                        else
                                break
                        fi
                fi
        sleep 0.5
        done
        ((++i))
done

cat page_scrape | sort -n | uniq > topic_scrape && rm page_scrape 
echo "[DEBUG][SCRAPER] Topic scraping; Start: $start_time; End: $(date); Topics scraped: $(cat topic_scrape | wc -l);" >> rutrsaver.log

